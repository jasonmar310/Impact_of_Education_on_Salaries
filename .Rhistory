train_set$Job.Title <- as.factor(train_set$Job.Title)
test_set$Job.Title <- as.factor(test_set$Job.Title)
# Fit the one-way ANOVA model
model <- aov(Salary ~ Job.Title, data = train_set)
# Summarize the model
summary(model)
# Load the required libraries
library(caret)
# Create a data partition
set.seed(123)
train_index <- createDataPartition(data$Salary, p = 0.8, list = FALSE)
train_set <- data[train_index, ]
test_set <- data[-train_index, ]
# Convert the Education.Level and Job.Title columns into factors
train_set$Education.Level <- as.factor(train_set$Education.Level)
test_set$Education.Level <- as.factor(test_set$Education.Level)
train_set$Job.Title <- as.factor(train_set$Job.Title)
test_set$Job.Title <- as.factor(test_set$Job.Title)
# Fit the multiple linear regression model
model <- lm(Salary ~ Education.Level + Years.of.Experience + Age + Job.Title, data = train_set)
# Summarize the model
summary(model)
# Predict the salaries on the test set
predictions <- predict(model, newdata = test_set)
# Calculate the mean squared error
mse <- mean((test_set$Salary - predictions)^2)
mse
# Load the required libraries
library(caret)
# Create a data partition
set.seed(123)
train_index <- createDataPartition(data$Salary, p = 0.8, list = FALSE)
train_set <- data[train_index, ]
test_set <- data[-train_index, ]
# Convert the Education.Level column into a factor
train_set$Education.Level <- as.factor(train_set$Education.Level)
test_set$Education.Level <- as.factor(test_set$Education.Level)
# Define k-fold cross-validation settings
k <- 10
folds <- createFolds(train_set$Salary, k = k, list = TRUE)
# Initialize variable to store the mean squared error of each fold
mse_values <- numeric(k)
# Perform k-fold cross-validation
for (i in 1:k) {
train_cv <- train_set[-folds[[i]], ]
valid_cv <- train_set[folds[[i]], ]
# Fit the multiple linear regression model without Job.Title
model <- lm(Salary ~ Education.Level + Years.of.Experience + Age, data = train_cv)
# Predict the salaries on the validation set
predictions <- predict(model, newdata = valid_cv)
# Calculate the mean squared error for the current fold
mse_values[i] <- mean((valid_cv$Salary - predictions)^2)
}
# Calculate the average mean squared error across all folds
mean_mse <- mean(mse_values)
mean_mse
# Visualization for predicted and actual salaries
# Create a data frame with the actual and predicted salaries
plot_data <- data.frame(ActualSalary = test_set$Salary, PredictedSalary = predictions)
# Create the scatter plot
ggplot(plot_data, aes(x = PredictedSalary, y = ActualSalary)) +
geom_point(color = "blue") +
geom_abline(slope = 1, intercept = 0, color = "red", linetype = "dashed") +
theme_minimal() +
labs(title = "Actual vs. Predicted Salaries",
x = "Predicted Salary",
y = "Actual Salary") +
theme(plot.title = element_text(hjust = 0.5))
mse
mean_mse
# Q2
# Load required libraries
library(caret)
# Create a data partition
set.seed(10)
train_index <- createDataPartition(data$Salary, p = 0.8, list = FALSE)
train_set <- data[train_index, ]
test_set <- data[-train_index, ]
# Convert the Education.Level column into a factor
train_set$Education.Level <- as.factor(train_set$Education.Level)
test_set$Education.Level <- as.factor(test_set$Education.Level)
# Fit the multiple linear regression model
model <- lm(Salary ~ Education.Level + Years.of.Experience + Age, data = train_set)
# Summarize the model
summary(model)
# Predict the salaries on the test set
predictions <- predict(model, newdata = test_set)
# Calculate the mean squared error
mse <- mean((test_set$Salary - predictions)^2)
mse
# Create a data partition
set.seed(10)
train_index <- createDataPartition(data$Salary, p = 0.8, list = FALSE)
train_set <- data[train_index, ]
test_set <- data[-train_index, ]
# Convert the Education.Level column into a factor
train_set$Education.Level <- as.factor(train_set$Education.Level)
test_set$Education.Level <- as.factor(test_set$Education.Level)
# Define k-fold cross-validation settings
k <- 10
folds <- createFolds(train_set$Salary, k = k, list = TRUE)
# Initialize variable to store the mean squared error of each fold
mse_values <- numeric(k)
# Perform k-fold cross-validation
for (i in 1:k) {
train_cv <- train_set[-folds[[i]], ]
valid_cv <- train_set[folds[[i]], ]
# Fit the multiple linear regression model without Job.Title
model <- lm(Salary ~ Education.Level + Years.of.Experience + Age, data = train_cv)
# Predict the salaries on the validation set
predictions <- predict(model, newdata = valid_cv)
# Calculate the mean squared error for the current fold
mse_values[i] <- mean((valid_cv$Salary - predictions)^2)
}
# Calculate the average mean squared error across all folds
mean_mse <- mean(mse_values)
mean_mse
# Initialize an empty list to store predictions and actual values
predictions_list <- list()
actual_values_list <- list()
# Perform k-fold cross-validation
for (i in 1:k) {
train_cv <- train_set[-folds[[i]], ]
valid_cv <- train_set[folds[[i]], ]
# Fit the multiple linear regression model without Job.Title
model <- lm(Salary ~ Education.Level + Years.of.Experience + Age, data = train_cv)
# Predict the salaries on the validation set
predictions <- predict(model, newdata = valid_cv)
# Store predictions and actual values in the lists
predictions_list[[i]] <- predictions
actual_values_list[[i]] <- valid_cv$Salary
}
# Combine predictions and actual values into data frames
predictions_df <- data.frame(Predicted = unlist(predictions_list))
actual_values_df <- data.frame(Actual = unlist(actual_values_list))
# Merge data frames
plot_data <- cbind(predictions_df, actual_values_df)
# Create a scatterplot of predicted vs actual values
ggplot(plot_data, aes(x = Actual, y = Predicted)) +
geom_point() +
geom_abline(intercept = 0, slope = 1, color = "red", linetype = "dashed") +
theme_minimal() +
xlab("Actual Salary") +
ylab("Predicted Salary") +
ggtitle("Scatterplot of Predicted vs Actual Salaries")
# Q2
# Load required libraries
library(caret)
# Create a data partition
set.seed(10)
train_index <- createDataPartition(data$Salary, p = 0.8, list = FALSE)
train_set <- data[train_index, ]
test_set <- data[-train_index, ]
# Convert the Education.Level column into a factor
train_set$Education.Level <- as.factor(train_set$Education.Level)
test_set$Education.Level <- as.factor(test_set$Education.Level)
# Fit the multiple linear regression model
model <- lm(Salary ~ Education.Level + Years.of.Experience + Age, data = train_set)
# Summarize the model
summary(model)
# Predict the salaries on the test set
predictions <- predict(model, newdata = test_set)
# Calculate the mean squared error
mse <- mean((test_set$Salary - predictions)^2)
mse
# Create a data partition
set.seed(10)
train_index <- createDataPartition(data$Salary, p = 0.8, list = FALSE)
train_set <- data[train_index, ]
test_set <- data[-train_index, ]
# Convert the Education.Level column into a factor
train_set$Education.Level <- as.factor(train_set$Education.Level)
test_set$Education.Level <- as.factor(test_set$Education.Level)
# Define k-fold cross-validation settings
k <- 10
folds <- createFolds(train_set$Salary, k = k, list = TRUE)
# Initialize variable to store the mean squared error of each fold
mse_values <- numeric(k)
# Perform k-fold cross-validation
for (i in 1:k) {
train_cv <- train_set[-folds[[i]], ]
valid_cv <- train_set[folds[[i]], ]
# Fit the multiple linear regression model without Job.Title
model <- lm(Salary ~ Education.Level + Years.of.Experience + Age, data = train_cv)
# Predict the salaries on the validation set
predictions <- predict(model, newdata = valid_cv)
# Calculate the mean squared error for the current fold
mse_values[i] <- mean((valid_cv$Salary - predictions)^2)
}
# Calculate the average mean squared error across all folds
mean_mse <- mean(mse_values)
mean_mse
rmse
rmse <- mse**0.5
rmse
# Calculate the mean squared error
mse <- mean((test_set$Salary - predictions)^2)
mse
rmse <- mse**0.5
rmse
# Calculate the mean squared error
mse <- mean((test_set$Salary - predictions)^2)
mse
rmse <- mse**0.5
rmse
# Define k-fold cross-validation settings
k <- 10
folds <- createFolds(train_set$Salary, k = k, list = TRUE)
# Initialize variable to store the mean squared error of each fold
mse_values <- numeric(k)
# Perform k-fold cross-validation
for (i in 1:k) {
train_cv <- train_set[-folds[[i]], ]
valid_cv <- train_set[folds[[i]], ]
model <- lm(Salary ~ Education.Level + Years.of.Experience + Age, data = train_cv)
# Predict the salaries on the validation set
predictions <- predict(model, newdata = valid_cv)
# Calculate the mean squared error for the current fold
mse_values[i] <- mean((valid_cv$Salary - predictions)^2)
}
# Calculate the average mean squared error across all folds
mean_mse <- mean(mse_values)
mean_mse
mean_rmse <- mean_mse ** 0.5
mean_rmse
# Calculate the mean squared error
mse <- mean((test_set$Salary - predictions)^2)
mse
rmse <- mse**0.5
rmse
# Calculate the average mean squared error across all folds
mean_mse <- mean(mse_values)
mean_mse
mean_rmse <- mean_mse ** 0.5
mean_rmse
# Q2
# Load required libraries
library(caret)
# Create a data partition
set.seed(10)
train_index <- createDataPartition(data$Salary, p = 0.8, list = FALSE)
train_set <- data[train_index, ]
test_set <- data[-train_index, ]
# Convert the Education.Level column into a factor
train_set$Education.Level <- as.factor(train_set$Education.Level)
test_set$Education.Level <- as.factor(test_set$Education.Level)
# Fit the multiple linear regression model
model <- lm(Salary ~ Education.Level + Years.of.Experience + Age, data = train_set)
# Summarize the model
summary(model)
# Predict the salaries on the test set
predictions <- predict(model, newdata = test_set)
# Calculate the mean squared error
mse <- mean((test_set$Salary - predictions)^2)
mse
rmse <- mse**0.5
rmse
k <- 10
folds <- createFolds(train_set$Salary, k = k, list = TRUE)
# Initialize variable to store the mean squared error of each fold
mse_values <- numeric(k)
# Perform k-fold cross-validation
for (i in 1:k) {
train_cv <- train_set[-folds[[i]], ]
valid_cv <- train_set[folds[[i]], ]
model <- lm(Salary ~ Education.Level + Years.of.Experience + Age, data = train_cv)
# Predict the salaries on the validation set
predictions <- predict(model, newdata = valid_cv)
# Calculate the mean squared error for the current fold
mse_values[i] <- mean((valid_cv$Salary - predictions)^2)
}
# Calculate the average mean squared error across all folds
mean_mse <- mean(mse_values)
mean_mse
mean_rmse <- mean_mse ** 0.5
mean_rmse
library(dplyr)
library(ggplot2)
# Read data
data <- read.csv("datafile.csv", header=T)
data <- data.frame(data)
summary(data)
# Data cleaning
data <- na.omit(data)
# Check outliers
boxplot(data$Salary)
boxplot.stats(data$Salary)$out
# Convert grouping variable (Education.Level) as a factor
data$Education.Level <- as.factor(data$Education.Level)
is.factor(data$Education.Level)
# Numerical and graphical summaries
aggregate(data$Salary,by=list(data$Education.Level),summary)
aggregate(data$Salary,by=list(data$Education.Level),sd)
boxplot(data$Salary~data$Education.Level,data=data)
# Q1
# Test 1
# one-way ANOVA
m <- aov(data$Salary~data$Education.Level,data=data)
summary(m)
# Critical value
qf(0.95, 2, 370)
# Bonferroni
pairwise.t.test(data$Salary,data$Education.Level,p.adj="bonferroni")
# Tukeys Test of Honest Significance Test
tukey_results <- TukeyHSD(m)
tukey_results
# Create a tukey_df for data visualization
tukey_df <- data.frame(tukey_results$`data$Education.Level`)
colnames(tukey_df) <- c("diff", "conf.low", "conf.high", "adj.p.value")
# Add the pair of groups to the data frame
tukey_df$pair <- rownames(tukey_df)
# Calculate the mean difference for each pair
tukey_df$mean_diff <- tukey_df$diff
# Plot the mean differences and confidence intervals
ggplot(tukey_df, aes(x = pair, y = mean_diff, ymin = conf.low, ymax = conf.high, color = adj.p.value < 0.05)) +
geom_pointrange() +
theme_minimal() +
labs(x = "Pairwise Comparisons", y = "Mean Difference", title = "TukeyHSD Results") +
geom_hline(yintercept = 0, linetype = "dashed") +
theme(legend.position = "none") +
coord_flip()
# Test 2
# Fit linear regression model
lm_model <- lm(Salary ~ Education.Level, data = data)
summary(lm_model)
# Residual plot
par(mfrow=c(2,2))
plot(lm_model)
# Plot the outliers
plot(lm_model,4)
# Remove outlier points from model
data1 <- data %>% filter(!row_number() %in% c(145))
lm_model2 <- lm(Salary ~ Education.Level, data = data1)
summary(lm_model2)
# Confidence Interval
confint(lm_model,level = 0.95)
confint(lm_model2, level=0.95)
# Calculate mean salary for each education level
mean_salaries <- aggregate(data$Salary, by=list(data$Education.Level), mean)
# Plot the mean salaries for different education levels
ggplot(mean_salaries, aes(x = Group.1, y = x, fill = Group.1)) +
geom_bar(stat = "identity", width = 0.5) +
theme_minimal() +
labs(x = "Education Level", y = "Mean Salary", title = "Mean Salaries by Education Level") +
theme(legend.position = "none")
# Q2
# Load required libraries
library(caret)
# Create a data partition
set.seed(10)
train_index <- createDataPartition(data$Salary, p = 0.8, list = FALSE)
train_set <- data[train_index, ]
test_set <- data[-train_index, ]
# Convert the Education.Level column into a factor
train_set$Education.Level <- as.factor(train_set$Education.Level)
test_set$Education.Level <- as.factor(test_set$Education.Level)
# Fit the multiple linear regression model
model <- lm(Salary ~ Education.Level + Years.of.Experience + Age, data = train_set)
# Summarize the model
summary(model)
# Predict the salaries on the test set
predictions <- predict(model, newdata = test_set)
# Calculate the mean squared error
mse <- mean((test_set$Salary - predictions)^2)
mse
rmse <- mse**0.5
rmse
# Define k-fold cross-validation settings
k <- 10
folds <- createFolds(train_set$Salary, k = k, list = TRUE)
# Initialize variable to store the mean squared error of each fold
mse_values <- numeric(k)
# Perform k-fold cross-validation
for (i in 1:k) {
train_cv <- train_set[-folds[[i]], ]
valid_cv <- train_set[folds[[i]], ]
model <- lm(Salary ~ Education.Level + Years.of.Experience + Age, data = train_cv)
# Predict the salaries on the validation set
predictions <- predict(model, newdata = valid_cv)
# Calculate the mean squared error for the current fold
mse_values[i] <- mean((valid_cv$Salary - predictions)^2)
}
# Calculate the average mean squared error across all folds
mean_mse <- mean(mse_values)
mean_mse
mean_rmse <- mean_mse ** 0.5
mean_rmse
# Plot the predicted model
# Initialize an empty list to store predictions and actual values
predictions_list <- list()
actual_values_list <- list()
# Perform k-fold cross-validation
for (i in 1:k) {
train_cv <- train_set[-folds[[i]], ]
valid_cv <- train_set[folds[[i]], ]
model <- lm(Salary ~ Education.Level + Years.of.Experience + Age, data = train_cv)
# Predict the salaries on the validation set
predictions <- predict(model, newdata = valid_cv)
# Store predictions and actual values in the lists
predictions_list[[i]] <- predictions
actual_values_list[[i]] <- valid_cv$Salary
}
# Combine predictions and actual values into data frames
predictions_df <- data.frame(Predicted = unlist(predictions_list))
actual_values_df <- data.frame(Actual = unlist(actual_values_list))
# Merge df
plot_data <- cbind(predictions_df, actual_values_df)
# Create a scatterplot of predicted vs actual values
ggplot(plot_data, aes(x = Actual, y = Predicted)) +
geom_point() +
geom_abline(intercept = 0, slope = 1, color = "red", linetype = "dashed") +
theme_minimal() +
xlab("Actual Salary") +
ylab("Predicted Salary") +
ggtitle("Scatterplot of Predicted vs Actual Salaries")
# Create a scatterplot of predicted vs actual values
ggplot(plot_data, aes(x = Actual, y = Predicted)) +
geom_point() +
geom_abline(intercept = 0, slope = 1, color = "red", linetype = "dashed") +
theme_minimal() +
xlab("Actual Salary") +
ylab("Predicted Salary") +
ggtitle("Scatterplot of Predicted vs Actual Salaries")
# Plot the predicted model
# Initialize an empty list to store predictions and actual values
predictions_list <- list()
actual_values_list <- list()
# Perform k-fold cross-validation
for (i in 1:k) {
train_cv <- train_set[-folds[[i]], ]
valid_cv <- train_set[folds[[i]], ]
model <- lm(Salary ~ Education.Level + Years.of.Experience + Age, data = train_cv)
# Predict the salaries on the validation set
predictions <- predict(model, newdata = valid_cv)
# Store predictions and actual values in the lists
predictions_list[[i]] <- predictions
actual_values_list[[i]] <- valid_cv$Salary
}
# Combine predictions and actual values into data frames
predictions_df <- data.frame(Predicted = unlist(predictions_list))
actual_values_df <- data.frame(Actual = unlist(actual_values_list))
# Merge df
plot_data <- cbind(predictions_df, actual_values_df)
# Create a scatterplot of predicted vs actual values
ggplot(plot_data, aes(x = Actual, y = Predicted)) +
geom_point() +
geom_abline(intercept = 0, slope = 1, color = "red", linetype = "dashed") +
theme_minimal() +
xlab("Actual Salary") +
ylab("Predicted Salary") +
ggtitle("Scatterplot of Predicted vs Actual Salaries")
train_index <- createDataPartition(data$Salary, p = 0.8, list = FALSE)
train_set <- data[train_index, ]
test_set <- data[-train_index, ]
# Plot the predicted model
# Initialize an empty list to store predictions and actual values
predictions_list <- list()
actual_values_list <- list()
# Perform k-fold cross-validation
for (i in 1:k) {
train_cv <- train_set[-folds[[i]], ]
valid_cv <- train_set[folds[[i]], ]
model <- lm(Salary ~ Education.Level + Years.of.Experience + Age, data = train_cv)
# Predict the salaries on the validation set
predictions <- predict(model, newdata = valid_cv)
# Store predictions and actual values in the lists
predictions_list[[i]] <- predictions
actual_values_list[[i]] <- valid_cv$Salary
}
# Combine predictions and actual values into data frames
predictions_df <- data.frame(Predicted = unlist(predictions_list))
actual_values_df <- data.frame(Actual = unlist(actual_values_list))
# Merge df
plot_data <- cbind(predictions_df, actual_values_df)
# Create a scatterplot of predicted vs actual values
ggplot(plot_data, aes(x = Actual, y = Predicted)) +
geom_point() +
geom_abline(intercept = 0, slope = 1, color = "red", linetype = "dashed") +
theme_minimal() +
xlab("Actual Salary") +
ylab("Predicted Salary") +
ggtitle("Scatterplot of Predicted vs Actual Salaries")
# Load the required libraries
library(ggplot2)
# Initialize an empty list to store predictions and actual values
predictions_list <- list()
actual_values_list <- list()
# Perform k-fold cross-validation
for (i in 1:k) {
train_cv <- train_set[-folds[[i]], ]
valid_cv <- train_set[folds[[i]], ]
# Fit the multiple linear regression model without Job.Title
model <- lm(Salary ~ Education.Level + Years.of.Experience + Age, data = train_cv)
# Predict the salaries on the validation set
predictions <- predict(model, newdata = valid_cv)
# Store predictions and actual values in the lists
predictions_list[[i]] <- predictions
actual_values_list[[i]] <- valid_cv$Salary
}
# Combine predictions and actual values into data frames
predictions_df <- data.frame(Predicted = unlist(predictions_list))
actual_values_df <- data.frame(Actual = unlist(actual_values_list))
# Merge data frames
plot_data <- cbind(predictions_df, actual_values_df)
# Create a scatterplot of predicted vs actual values
ggplot(plot_data, aes(x = Actual, y = Predicted)) +
geom_point() +
geom_abline(intercept = 0, slope = 1, color = "red", linetype = "dashed") +
theme_minimal() +
xlab("Actual Salary") +
ylab("Predicted Salary") +
ggtitle("Scatterplot of Predicted vs Actual Salaries")
